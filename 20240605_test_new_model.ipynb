{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After rewriting/refactoring of code base, do a test pipeline from start to end to see if everything works in principle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 21:15:54.843974: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-06-05 21:15:55.009340: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-06-05 21:15:55.187807: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-05 21:16:24.146429: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import logging\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "from time import time\n",
    "\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'modules.Links' from '/home/ebelm/genomegraph/learn_specific_profiles/modules/Links.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from modules import SequenceRepresentation as sr\n",
    "from modules import ModelDataSet\n",
    "from modules import ProfileFindingSetup\n",
    "from modules import plotting\n",
    "from modules import model_new as model\n",
    "from modules import training_new as training\n",
    "from modules import Links\n",
    "\n",
    "importlib.reload(sr)\n",
    "importlib.reload(ModelDataSet)\n",
    "importlib.reload(ProfileFindingSetup)\n",
    "importlib.reload(plotting)\n",
    "importlib.reload(model)\n",
    "importlib.reload(Links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = Path(\"/home/ebelm/genomegraph/data/241_species/20231123_subset150_NM_RefSeqBest/20240605_fixed_out_subset150_withEnforced_20_15_20_50_15_20_15_20_mammals/exon_chr10_100356531_100356764/\")\n",
    "outpath  = Path(\"/home/ebelm/genomegraph/runs/20240605_testNewModel/\")\n",
    "os.makedirs(outpath, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = sr.loadJSONSequenceList(datapath / \"profile_finding_sequence_data.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:[makeAnnotationsUnique] Sequence Fukomys_damarensis:KN123008.1:2,409,178-2,440,546: Found and uniq-ed 0 redundant annotations; removed total of 0 redundant annotations\n",
      "INFO:root:[selectLongestTranscript] Found and removed subsequence annotations in {sequence}. Removed total of 0 subsequence annotations\n",
      "INFO:root:[makeAnnotationsUnique] Sequence Cercocebus_atys:KQ012652.1:5,274,598-5,280,660: Found and uniq-ed 1 redundant annotations; removed total of 1 redundant annotations\n",
      "INFO:root:[makeAnnotationsUnique] Sequence Saimiri_boliviensis:JH378110.1:32,223,310-32,229,802: Found and uniq-ed 1 redundant annotations; removed total of 1 redundant annotations\n",
      "INFO:root:[makeAnnotationsUnique] Sequence Hipposideros_armiger:JXIK01000029.1:2,457,613-2,462,101: Found and uniq-ed 0 redundant annotations; removed total of 0 redundant annotations\n",
      "INFO:root:[selectLongestTranscript] Found and removed subsequence annotations in {sequence}. Removed total of 1 subsequence annotations\n"
     ]
    }
   ],
   "source": [
    "genomes: list[sr.Genome] = []\n",
    "for seq in sequences:\n",
    "    # make annotations and transkripts unique\n",
    "    sr.makeAnnotationsUnique(seq)\n",
    "    sr.selectLongestTranscript(seq)\n",
    "\n",
    "    g = sr.Genome()\n",
    "    g.addSequence(seq)\n",
    "    genomes.append(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shorten data so that it runs faster\n",
    "maxgenomes = 5\n",
    "maxseqlen = 3000\n",
    "\n",
    "genomes = genomes[:maxgenomes]\n",
    "for genome in genomes:\n",
    "    for seq in genome.sequences:\n",
    "        if len(seq) > maxseqlen:\n",
    "            d = len(seq) - maxseqlen\n",
    "            seq.stripSequence(d, from_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:[main] Start training and evaluation for run 0000\n",
      "INFO:root:[main] Start training and evaluation on model for 0000\n",
      "INFO:root:[ProfileFindingSetup.ProfileFindingTrainingSetup.initializeProfiles] >>> Number of profiles: 10\n",
      "WARNING:root:[ProfileFindingSetup.ProfileFindingTrainingSetup.initializeProfiles] >>> 10 profiles initialized, but 200 requested. Resetting U to 10\n",
      "DEBUG:root:[model.__init__] >>> setting tf global seed to 42\n",
      "DEBUG:root:[model.__init__] >>> Using initProfiles from training setup instead of random\n",
      "2024-06-05 21:17:58.554417: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-06-05 21:17:59.047008: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-06-05 21:17:59.497542: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "masked_sites_scores.shape=(441000,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m evaluator \u001b[38;5;241m=\u001b[39m training\u001b[38;5;241m.\u001b[39mMultiTrainingEvaluation()\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# try:\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m \u001b[43mtraining\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainAndEvaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrunID\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainsetup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevaluator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m                            \u001b[49m\u001b[43moutpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutprefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mrunID\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mtrainingWithReporting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrand_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSEED\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# except Exception as e:\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m#     logging.error(f\"[main] trainAndEvaluate failed for homology {0}, check log for details\")\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m#     logging.error(f\"[main] Error message: {e}\")\u001b[39;00m\n\u001b[1;32m     20\u001b[0m evaluator\u001b[38;5;241m.\u001b[39mdump(outpath \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevaluator.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/genomegraph/learn_specific_profiles/modules/training_new.py:335\u001b[0m, in \u001b[0;36mtrainAndEvaluate\u001b[0;34m(runID, trainsetup, evaluator, outdir, outprefix, trainingWithReporting, rand_seed)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;66;03m# build and randomly initialize profile model\u001b[39;00m\n\u001b[1;32m    334\u001b[0m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39mclear_session() \u001b[38;5;66;03m# avoid memory cluttering by remains of old models\u001b[39;00m\n\u001b[0;32m--> 335\u001b[0m specProModel \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSpecificProfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43msetup\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrainsetup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mrand_seed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrand_seed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;66;03m# start training\u001b[39;00m\n\u001b[1;32m    339\u001b[0m start \u001b[38;5;241m=\u001b[39m time()\n",
      "File \u001b[0;32m~/genomegraph/learn_specific_profiles/modules/model_new.py:243\u001b[0m, in \u001b[0;36mSpecificProfile.__init__\u001b[0;34m(self, setup, rand_seed, **kwargs)\u001b[0m\n\u001b[1;32m    240\u001b[0m losses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_mean_losses(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mgetDataset(withPosTracking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m), P \u001b[38;5;241m=\u001b[39m Pt)\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m    241\u001b[0m sites, site_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_profile_match_sites(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mgetDataset(withPosTracking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m), Pt, \n\u001b[1;32m    242\u001b[0m                                                   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msetup\u001b[38;5;241m.\u001b[39mmatch_score_factor \u001b[38;5;241m*\u001b[39m scores)\n\u001b[0;32m--> 243\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprofile_tracking\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maddEpoch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlosses\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msites\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msite_scores\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/genomegraph/learn_specific_profiles/modules/model_new.py:101\u001b[0m, in \u001b[0;36mProfileTracking.addEpoch\u001b[0;34m(self, epoch, P, max_scores, mean_losses, masked_sites, masked_sites_scores)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(masked_sites\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmasked_sites\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m masked_sites\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m6\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmasked_sites\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 101\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(masked_sites_scores\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmasked_sites_scores\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m masked_sites_scores\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmasked_sites_scores\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch\u001b[38;5;241m.\u001b[39mappend(epoch)\n",
      "\u001b[0;31mAssertionError\u001b[0m: masked_sites_scores.shape=(441000,)"
     ]
    }
   ],
   "source": [
    "runID = \"0000\"\n",
    "starttime = time()\n",
    "logging.info(f\"[main] Start training and evaluation for run {runID}\")\n",
    "\n",
    "# --- train our model (DNA mode) ---\n",
    "logging.info(f\"[main] Start training and evaluation on model for {runID}\")\n",
    "data = ModelDataSet.ModelDataSet(genomes, ModelDataSet.DataMode.DNA,\n",
    "                                 tiles_per_X = 7, tile_size = 334)\n",
    "trainsetup = ProfileFindingSetup.ProfileFindingTrainingSetup(data, U = 200, n_best_profiles=1)\n",
    "trainsetup.initializeProfiles_kmers(enforceU=False, plot=False, overlapTilesize=6)\n",
    "evaluator = training.MultiTrainingEvaluation()\n",
    "# try:\n",
    "training.trainAndEvaluate(runID, trainsetup, evaluator, \n",
    "                            outpath, outprefix=f\"{runID}_\", \n",
    "                            trainingWithReporting=True, rand_seed=SEED)\n",
    "# except Exception as e:\n",
    "#     logging.error(f\"[main] trainAndEvaluate failed for homology {0}, check log for details\")\n",
    "#     logging.error(f\"[main] Error message: {e}\")\n",
    "\n",
    "evaluator.dump(outpath / \"evaluator.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
