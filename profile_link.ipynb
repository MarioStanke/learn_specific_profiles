{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom ML model to identify local similarities (\"links\") with sequence profiles\n",
    "\n",
    "Let $$X \\in \\{0,1\\}^{B\\times N\\times 6 \\times T \\times 21}$$ be a batch of **one-hot encoded input translated sequences**,\n",
    "where $B$ is `batch_size`, $N$ is the number of genomes and $T$ is the `tile_size` (in aa).\n",
    "The 6 is here the number of translated frames in order (0,+),(1,+),(2,+),(0,-),(1,-),(2,-).\n",
    "The 21 is here the size of the considered amino acid alphabet.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'sequtils' from '/home/jovyan/brain/genomegraph/learn_specific_profiles/sequtils.py'>\n",
      "<module 'seq' from '/home/jovyan/brain/genomegraph/learn_specific_profiles/seq.py'>\n",
      "<module 'dataset' from '/home/jovyan/brain/genomegraph/learn_specific_profiles/dataset.py'>\n",
      "<module 'model' from '/home/jovyan/brain/genomegraph/learn_specific_profiles/model.py'>\n",
      "2.5.0\n"
     ]
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import logomaker\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "from IPython.display import Audio\n",
    "\n",
    "import importlib\n",
    "import sequtils as su\n",
    "print(importlib.reload(su))\n",
    "import seq\n",
    "print(importlib.reload(seq))\n",
    "import dataset as dsg\n",
    "print(importlib.reload(dsg))\n",
    "import model\n",
    "print(importlib.reload(model))\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_real_data = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create random genomes as toy data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pattern AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA translates to  ['REPEATAEPER', 'ENLKLLLNLK', 'RT*SYC*T*K', 'SFRFSSSFRFS', 'LSGSAVASGS', 'FQVQQ*LQVL']\n",
      "  mutated to AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA and inserted in genome 0 contig 0 at position 9422\n",
      "  mutated to AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA and inserted in genome 0 contig 0 at position 8432\n",
      "  mutated to AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA and inserted in genome 0 contig 0 at position 6250\n",
      "  mutated to AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA and inserted in genome 0 contig 0 at position 3996\n",
      "  mutated to AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA and inserted in genome 0 contig 0 at position 3624\n",
      "  mutated to AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA and inserted in genome 0 contig 0 at position 8390\n",
      "  mutated to AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA and inserted in genome 0 contig 0 at position 9193\n",
      "  mutated to AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA and inserted in genome 0 contig 0 at position 4802\n",
      "  mutated to AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA and inserted in genome 0 contig 0 at position 7482\n",
      "  mutated to AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA and inserted in genome 0 contig 0 at position 679\n",
      "  mutated to AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA and inserted in genome 1 contig 0 at position 1064\n",
      "  mutated to AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA and inserted in genome 1 contig 0 at position 7205\n",
      "  mutated to AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA and inserted in genome 1 contig 0 at position 8368\n",
      "  mutated to AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA and inserted in genome 1 contig 0 at position 205\n",
      "  mutated to AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA and inserted in genome 1 contig 0 at position 3134\n",
      "  mutated to AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA and inserted in genome 1 contig 0 at position 4208\n",
      "  mutated to AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA and inserted in genome 1 contig 0 at position 7614\n",
      "  mutated to AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA and inserted in genome 1 contig 0 at position 8082\n",
      "  mutated to AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA and inserted in genome 1 contig 0 at position 6824\n",
      "  mutated to AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA and inserted in genome 1 contig 0 at position 8716\n",
      "  mutated to AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA and inserted in genome 2 contig 0 at position 1978\n",
      "  mutated to AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA and inserted in genome 2 contig 0 at position 9453\n",
      "  mutated to AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA and inserted in genome 2 contig 0 at position 9960\n",
      "  mutated to AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA and inserted in genome 2 contig 0 at position 8913\n",
      "  mutated to AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA and inserted in genome 2 contig 0 at position 3439\n",
      "  mutated to AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA and inserted in genome 2 contig 0 at position 9423\n",
      "  mutated to AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA and inserted in genome 2 contig 0 at position 3612\n",
      "  mutated to AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA and inserted in genome 2 contig 0 at position 4953\n",
      "  mutated to AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA and inserted in genome 2 contig 0 at position 2964\n",
      "  mutated to AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA and inserted in genome 2 contig 0 at position 2650\n",
      "  mutated to AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA and inserted in genome 3 contig 0 at position 8012\n",
      "  mutated to AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA and inserted in genome 3 contig 0 at position 2796\n",
      "  mutated to AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA and inserted in genome 3 contig 0 at position 1262\n",
      "  mutated to AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA and inserted in genome 3 contig 0 at position 722\n",
      "  mutated to AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA and inserted in genome 3 contig 0 at position 6294\n",
      "  mutated to AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA and inserted in genome 3 contig 0 at position 9006\n",
      "  mutated to AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA and inserted in genome 3 contig 0 at position 2602\n",
      "  mutated to AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA and inserted in genome 3 contig 0 at position 7787\n",
      "  mutated to AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA and inserted in genome 3 contig 0 at position 846\n",
      "  mutated to AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA and inserted in genome 3 contig 0 at position 3395\n",
      "  mutated to AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA and inserted in genome 4 contig 0 at position 2816\n",
      "  mutated to AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA and inserted in genome 4 contig 0 at position 8194\n",
      "  mutated to AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA and inserted in genome 4 contig 0 at position 5002\n",
      "  mutated to AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA and inserted in genome 4 contig 0 at position 2224\n",
      "  mutated to AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA and inserted in genome 4 contig 0 at position 7639\n",
      "  mutated to AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA and inserted in genome 4 contig 0 at position 1838\n",
      "  mutated to AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA and inserted in genome 4 contig 0 at position 5728\n",
      "  mutated to AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA and inserted in genome 4 contig 0 at position 6738\n",
      "  mutated to AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA and inserted in genome 4 contig 0 at position 6476\n",
      "  mutated to AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA and inserted in genome 4 contig 0 at position 1675\n",
      "  mutated to AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA and inserted in genome 5 contig 0 at position 1486\n",
      "  mutated to AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA and inserted in genome 5 contig 0 at position 6523\n",
      "  mutated to AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA and inserted in genome 5 contig 0 at position 8101\n",
      "  mutated to AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA and inserted in genome 5 contig 0 at position 3150\n",
      "  mutated to AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA and inserted in genome 5 contig 0 at position 1371\n",
      "  mutated to AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA and inserted in genome 5 contig 0 at position 7775\n",
      "  mutated to AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA and inserted in genome 5 contig 0 at position 8805\n",
      "  mutated to AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA and inserted in genome 5 contig 0 at position 548\n",
      "  mutated to AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA and inserted in genome 5 contig 0 at position 5356\n",
      "  mutated to AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA and inserted in genome 5 contig 0 at position 4985\n",
      "  mutated to AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA and inserted in genome 6 contig 0 at position 8751\n",
      "  mutated to AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA and inserted in genome 6 contig 0 at position 4106\n",
      "  mutated to AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA and inserted in genome 6 contig 0 at position 3579\n",
      "  mutated to AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA and inserted in genome 6 contig 0 at position 1326\n",
      "  mutated to AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA and inserted in genome 6 contig 0 at position 8105\n",
      "  mutated to AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA and inserted in genome 6 contig 0 at position 5093\n",
      "  mutated to AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA and inserted in genome 6 contig 0 at position 1831\n",
      "  mutated to AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA and inserted in genome 6 contig 0 at position 6654\n",
      "  mutated to AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA and inserted in genome 6 contig 0 at position 1256\n",
      "  mutated to AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA and inserted in genome 6 contig 0 at position 4679\n",
      "  mutated to AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA and inserted in genome 7 contig 0 at position 2779\n",
      "  mutated to AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA and inserted in genome 7 contig 0 at position 1757\n",
      "  mutated to AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA and inserted in genome 7 contig 0 at position 4645\n",
      "  mutated to AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA and inserted in genome 7 contig 0 at position 9329\n",
      "  mutated to AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA and inserted in genome 7 contig 0 at position 8482\n",
      "  mutated to AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA and inserted in genome 7 contig 0 at position 4050\n",
      "  mutated to AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA and inserted in genome 7 contig 0 at position 3325\n",
      "  mutated to AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA and inserted in genome 7 contig 0 at position 7851\n",
      "  mutated to AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA and inserted in genome 7 contig 0 at position 5988\n",
      "  mutated to AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA and inserted in genome 7 contig 0 at position 2775\n",
      "Pattern ATGGCAAGAATTCAATCTACTGCAAATAAAGAA translates to  ['MARIQSTANKE', 'WQEFNLLQIK', 'GKNSIYCK*R', 'FFICSRLNSCH', 'SLFAVD*ILA', 'LYLQ*IEFLP']\n",
      "  mutated to ATGGCAAGAATTCAATCTACTGCAAATAAAGAA and inserted in genome 0 contig 0 at position 3164\n",
      "  mutated to ATGGCAAGAATTCAATCTACTGCAAATAAAGAA and inserted in genome 1 contig 0 at position 3550\n",
      "  mutated to ATGGCAAGAATTCAATCTACTGCAAATAAAGAA and inserted in genome 2 contig 0 at position 716\n",
      "  mutated to ATGGCAAGAATTCAATCTACTGCAAATAAAGAA and inserted in genome 3 contig 0 at position 5787\n",
      "  mutated to ATGGCAAGAATTCAATCTACTGCAAATAAAGAA and inserted in genome 4 contig 0 at position 8275\n",
      "  mutated to ATGGCAAGAATTCAATCTACTGCAAATAAAGAA and inserted in genome 5 contig 0 at position 1606\n",
      "  mutated to ATGGCAAGAATTCAATCTACTGCAAATAAAGAA and inserted in genome 6 contig 0 at position 2941\n",
      "  mutated to ATGGCAAGAATTCAATCTACTGCAAATAAAGAA and inserted in genome 7 contig 0 at position 645\n",
      "insert: {0: {0: {'pos': [3164], 'pattern': ['ATGGCAAGAATTCAATCTACTGCAAATAAAGAA']}}, 1: {0: {'pos': [3550], 'pattern': ['ATGGCAAGAATTCAATCTACTGCAAATAAAGAA']}}, 2: {0: {'pos': [716], 'pattern': ['ATGGCAAGAATTCAATCTACTGCAAATAAAGAA']}}, 3: {0: {'pos': [5787], 'pattern': ['ATGGCAAGAATTCAATCTACTGCAAATAAAGAA']}}, 4: {0: {'pos': [8275], 'pattern': ['ATGGCAAGAATTCAATCTACTGCAAATAAAGAA']}}, 5: {0: {'pos': [1606], 'pattern': ['ATGGCAAGAATTCAATCTACTGCAAATAAAGAA']}}, 6: {0: {'pos': [2941], 'pattern': ['ATGGCAAGAATTCAATCTACTGCAAATAAAGAA']}}, 7: {0: {'pos': [645], 'pattern': ['ATGGCAAGAATTCAATCTACTGCAAATAAAGAA']}}}\n",
      "repeat: {0: {0: {'pos': [9422, 8432, 6250, 3996, 3624, 8390, 9193, 4802, 7482, 679], 'pattern': ['AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA', 'AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA', 'AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA', 'AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA', 'AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA', 'AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA', 'AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA', 'AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA', 'AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA', 'AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA']}}, 1: {0: {'pos': [1064, 7205, 8368, 205, 3134, 4208, 7614, 8082, 6824, 8716], 'pattern': ['AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA', 'AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA', 'AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA', 'AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA', 'AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA', 'AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA', 'AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA', 'AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA', 'AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA', 'AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA']}}, 2: {0: {'pos': [1978, 9453, 9960, 8913, 3439, 9423, 3612, 4953, 2964, 2650], 'pattern': ['AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA', 'AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA', 'AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA', 'AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA', 'AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA', 'AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA', 'AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA', 'AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA', 'AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA', 'AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA']}}, 3: {0: {'pos': [8012, 2796, 1262, 722, 6294, 9006, 2602, 7787, 846, 3395], 'pattern': ['AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA', 'AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA', 'AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA', 'AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA', 'AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA', 'AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA', 'AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA', 'AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA', 'AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA', 'AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA']}}, 4: {0: {'pos': [2816, 8194, 5002, 2224, 7639, 1838, 5728, 6738, 6476, 1675], 'pattern': ['AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA', 'AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA', 'AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA', 'AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA', 'AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA', 'AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA', 'AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA', 'AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA', 'AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA', 'AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA']}}, 5: {0: {'pos': [1486, 6523, 8101, 3150, 1371, 7775, 8805, 548, 5356, 4985], 'pattern': ['AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA', 'AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA', 'AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA', 'AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA', 'AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA', 'AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA', 'AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA', 'AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA', 'AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA', 'AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA']}}, 6: {0: {'pos': [8751, 4106, 3579, 1326, 8105, 5093, 1831, 6654, 1256, 4679], 'pattern': ['AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA', 'AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA', 'AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA', 'AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA', 'AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA', 'AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA', 'AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA', 'AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA', 'AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA', 'AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA']}}, 7: {0: {'pos': [2779, 1757, 4645, 9329, 8482, 4050, 3325, 7851, 5988, 2775], 'pattern': ['AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA', 'AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA', 'AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA', 'AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA', 'AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA', 'AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA', 'AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA', 'AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA', 'AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA', 'AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA']}}}\n"
     ]
    }
   ],
   "source": [
    "N = 8            # number of genomes\n",
    "tile_size = 334  # tile size measured in amino acids\n",
    "# A tile is a consecutive subsequence of _one_ contig/scaffold/chromosome.\n",
    "# Tiles should be about gene-sized.\n",
    "\n",
    "#genome_sizes = [[210,100], [30,220,150], [230,110,120,90], [180]] # in nucleotides\n",
    "#insertPatterns = [\"ATGATGATG\", \"CCCCCCCCCCCC\"]\n",
    "#genomes = seq.getRandomGenomes(N, genome_sizes, insertPatterns, mutationProb=0.2, verbose=True)\n",
    "\n",
    "genome_sizes = [[10000]] * N\n",
    "                # in nucleotides\n",
    "insertPatterns = [\"ATGGCAAGAATTCAATCTACTGCAAATAAAGAA\"] \n",
    "repeatPatterns = ['AGAGAACCTGAAGCTACTGCTGAACCTGAAAGA']\n",
    "genomes, repeatTracking, insertTracking = seq.getRandomGenomes(N, genome_sizes, insertPatterns,\n",
    "                                                               repeatPatterns,\n",
    "                                                               mutationProb=0.0, \n",
    "                                                               repeatMultiple=range(1,2),\n",
    "                                                               repeatInsert=range(10,11),\n",
    "                                                               verbose=True)\n",
    "print(\"insert:\", insertTracking)\n",
    "print(\"repeat:\", repeatTracking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    flat_genomes = []\n",
    "    tracking = {}\n",
    "    i = 0\n",
    "    for g in range(len(genomes)):\n",
    "        for c in range(len(genomes[g])):\n",
    "            flat_genomes.append(SeqRecord(Seq(genomes[g][c]),\n",
    "                                          id=str(i), description=\"\"))\n",
    "            tracking[i] = {'insert': dict(insertTracking[g][c]),\n",
    "                           'repeat': dict(repeatTracking[g][c])}\n",
    "            i += 1\n",
    "            \n",
    "    with open(\"artificial.fasta\", \"w\") as output_handle:\n",
    "        SeqIO.write(flat_genomes, output_handle, \"fasta\")\n",
    "        \n",
    "    with open(\"tracking.json\", \"w\") as fh:\n",
    "        json.dump(tracking, fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Desired: ['MARIQSTANKE', 'WQEFNLLQIK', 'GKNSIYCK*R', 'FFICSRLNSCH', 'SLFAVD*ILA', 'LYLQ*IEFLP']\n",
      "Repeat: ['REPEATAEPER', 'ENLKLLLNLK', 'RT*SYC*T*K', 'SFRFSSSFRFS', 'LSGSAVASGS', 'FQVQQ*LQVL']\n"
     ]
    }
   ],
   "source": [
    "def printExpectedPatterns():\n",
    "    desiredPatternAA, repeatPatternAA = None, None\n",
    "    if insertPatterns is not None:\n",
    "        desiredPatternAA = []\n",
    "        for pattern in insertPatterns:\n",
    "            desiredPatternAA.extend(su.six_frame_translation(pattern))\n",
    "\n",
    "        print(\"Desired:\", desiredPatternAA)\n",
    "\n",
    "    if repeatPatterns is not None:\n",
    "        repeatPatternAA = []\n",
    "        for pattern in repeatPatterns:\n",
    "            repeatPatternAA.extend(su.six_frame_translation(pattern))\n",
    "\n",
    "        print(\"Repeat:\", repeatPatternAA)\n",
    "        \n",
    "    return desiredPatternAA, repeatPatternAA\n",
    "\n",
    "desiredPatternAA, repeatPatternAA = printExpectedPatterns()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Interlude: Magic Commands\n",
    "\n",
    "https://towardsdatascience.com/speed-up-jupyter-notebooks-20716cbe2025\n",
    "\n",
    "`%time command` prints runtime of command  \n",
    "`%prun command` profiler for command, what steps take how much time? Adds overhead  \n",
    "`%memit command` peak memory usage and memory increment  \n",
    "`%mprun command` memory profiling\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "background freqs:  159968.0 *\n",
      "C 0.0306\n",
      "K 0.0315\n",
      "E 0.0333\n",
      "W 0.0153\n",
      "T 0.0619\n",
      "G 0.0616\n",
      "Y 0.0299\n",
      "A 0.0620\n",
      "I 0.0456\n",
      "N 0.0315\n",
      "V 0.0619\n",
      "H 0.0305\n",
      "S 0.0963\n",
      "D 0.0306\n",
      "F 0.0325\n",
      "M 0.0150\n",
      "R 0.0925\n",
      "L 0.0957\n",
      "P 0.0616\n",
      "Q 0.0323\n",
      "* 0.0479\n",
      "CPU times: user 50.4 ms, sys: 0 ns, total: 50.4 ms\n",
      "Wall time: 49.9 ms\n"
     ]
    }
   ],
   "source": [
    "# Load Real Data\n",
    "if use_real_data:    \n",
    "    files = ['hg38.fa', 'mm10.fa', 'hetGla2.fa', 'macFas5.fa']\n",
    "    genomes = [[] for _ in range(len(files))]\n",
    "    seqnames = [[] for _ in range(len(files))]\n",
    "    datapath = \"../data/20210517_flanked/subset\"\n",
    "    def loadRealGenomes(genomes=genomes):\n",
    "        for i in range(len(files)):\n",
    "            genomes[i].extend([str(seq.seq) for seq in SeqIO.parse(os.path.join(datapath, files[i]), 'fasta')])\n",
    "            seqnames[i].extend([str(seq.id) for seq in SeqIO.parse(os.path.join(datapath, files[i]), 'fasta')])\n",
    "            \n",
    "    %memit loadRealGenomes()\n",
    "    \n",
    "    # load pickled Q to safe time\n",
    "    Qfile = os.path.join(datapath, \"backgroundAAFreqs.pkl4\")\n",
    "    if not os.path.isfile(Qfile):\n",
    "        print(\"Getting Q\")\n",
    "        %time Q = seq.backGroundAAFreqs(genomes, True)\n",
    "        with open(Qfile, 'wb') as fh:\n",
    "            pickle.dump(Q, fh, protocol=4)\n",
    "            \n",
    "    else:\n",
    "        with open(Qfile, 'rb') as fh:\n",
    "            Q = pickle.load(fh)\n",
    "    \n",
    "else:\n",
    "    %time Q = seq.backGroundAAFreqs(genomes, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For seedFinding data on gs3\n",
    "\n",
    "    background freqs:  765611260.0 *\n",
    "    C 0.0329\n",
    "    K 0.0412\n",
    "    E 0.0332\n",
    "    W 0.0165\n",
    "    T 0.0578\n",
    "    G 0.0558\n",
    "    Y 0.0334\n",
    "    A 0.0510\n",
    "    I 0.0546\n",
    "    N 0.0361\n",
    "    V 0.0578\n",
    "    H 0.0321\n",
    "    S 0.0929\n",
    "    D 0.0280\n",
    "    F 0.0406\n",
    "    M 0.0172\n",
    "    R 0.0710\n",
    "    L 0.1039\n",
    "    P 0.0558\n",
    "    Q 0.0352\n",
    "    * 0.0527\n",
    "    CPU times: user 7min 14s, sys: 1.69 s, total: 7min 16s\n",
    "    Wall time: 7min 16s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 1 10000\n"
     ]
    }
   ],
   "source": [
    "print(len(genomes), len(genomes[0]), len(genomes[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uniform background distribution appears to be rather better\n",
    "Q = np.ones(21, dtype=np.float32)/21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in the genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AGACTATGTTGGGAAGGGAGTCACCGTGGTATTCCATAGCTAGTGGTAGGCCGTAGCTCCTGGGCCGCCTTATGATATATCGAGAGCGAGCTAGTTTACA'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genomes[0][0][0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] >>> Test genome lengths: [10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:02,  1.16s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] >>> testGenerator - restore sequences: All good\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:16,  8.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] >>> testGenerator - restore positions: All good\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dsg.testGenerator(genomes, 5, tile_size, 50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000]  ->  1\n"
     ]
    }
   ],
   "source": [
    "genome_sizes = [sum([len(s) for s in genome]) for genome in genomes]\n",
    "batch_size = 1  # number of X to generate per batch\n",
    "tiles_per_X = 13 # number of tiles per X (-> X.shape[0])\n",
    "steps_per_epoch = max(1, np.mean(genome_sizes) // (batch_size*tiles_per_X*tile_size*3))\n",
    "print(genome_sizes, \" -> \", steps_per_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Plot Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotLogo(P, idxarray = None, pScores = None, max_print=5, label=\"score\"):\n",
    "    \"\"\"\n",
    "    max_print  print up to this many logos\n",
    "    \"\"\"\n",
    "    dfs = su.makeDFs(P.numpy())\n",
    "    for i in range(min(P.shape[2],max_print)):\n",
    "        j = idxarray[i] if idxarray is not None else i\n",
    "        profile_df = dfs[j]\n",
    "        logo = logomaker.Logo(profile_df, vpad=.1, width=1)\n",
    "        logo.style_xticks(anchor=0, spacing=1, rotation=45)\n",
    "        logo.ax.set_ylabel('information (bits)')\n",
    "        logo.ax.set_title(f\"Profile {j}\" + (f\" {label}={pScores[j]:.3f}\") if pScores is not None else \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training history as loss and accuracy curves\n",
    "def plotHistory(history):\n",
    "    loss = history['loss']\n",
    "    Rmax = history['Rmax']\n",
    "    Rmin = history['Rmin']\n",
    "    Smax = history['Smax']\n",
    "    Smin = history['Smin']\n",
    "    epochs = range(1, len(loss) + 1)\n",
    "\n",
    "    fig, ax = plt.subplots(ncols = 2, figsize = (15, 6))\n",
    "    ax[0].plot(epochs, loss, 'bo', label = 'Training loss')\n",
    "    ax[0].set_title('Training loss')\n",
    "    ax[0].legend()\n",
    "\n",
    "    ax[1].plot(epochs, Rmax, 'bo', label = 'Rmax')\n",
    "    ax[1].plot(epochs, Rmin, 'b+', label = 'Rmin')\n",
    "    ax[1].plot(epochs, Smax, 'go', label = 'Smax')\n",
    "    ax[1].plot(epochs, Smin, 'g+', label = 'Smin')\n",
    "    ax[1].set_title('Training R and S')\n",
    "    ax[1].legend();\n",
    "    \n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow Model\n",
    "Let $$P = (P[w,c,u]) \\in [0,1]^{k \\times 21 \\times U}$$\n",
    "be a collection of $U$ amino acid **profiles**, each of length $k$.\n",
    "Let $$ Q = (Q[c]) \\in [0,1]^{21}$$ be a background amino acid distribution.\n",
    "\n",
    "Both are normalized distributions:\n",
    "$$ \\sum_c P[w,c,u] = \\sum_c Q[c] = 1 \\qquad \\forall u,w.$$\n",
    "\n",
    "Define the scores tensor \n",
    "$$ S \\in \\mathbb{R}^ {B\\times N \\times U}$$\n",
    "by\n",
    "$$ S[b,g,u] = \\max_{f=0}^5 \\max_{v=0}^{T-k} \\sum_{w=0}^{k-1} \\sum_{c=0}^{20} X[b,g,f,v+w,c] \\cdot \\ln \\frac {P[w,c,u]}{Q[c]}.$$\n",
    "\n",
    "For a given batch $S[b,g,u]$ is the maximal score that the $u$-th profile scores in the $b$-th tile of genome $g$.\n",
    "It can be computed using a **one dimensional convolution** and max pooling.\n",
    "\n",
    "Define the intermediate variables:\n",
    "\n",
    "$R \\in [0,1]^{k \\times 21 \\times U}$ by \n",
    "$$ R[w,c,u] := \\ln \\frac {P[w,c,u]}{Q[c]}.$$\n",
    "\n",
    "$Z \\in \\mathbb{R}^{B\\times N \\times 6 \\times T-k-1\\times U}$ by\n",
    "$$Z[b,g,f,v,u] := \\sum_{w=0}^{k-1} \\sum_{c=0}^{20} X[b,g,f,v+w,c] \\cdot R[w,c,u].$$\n",
    "\n",
    "**Losses:**\n",
    "Only the best score counts for each frame and tile. Sum them up.\n",
    "$$L_1 = - \\sum_{b=1}^B \\sum_{g=1}^G \\sum_{u=1}^U S[b,g,u]$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "U = 200 # number of profiles to train\n",
    "k = 11 # length of profiles\n",
    "alpha = 1e-6 # loss norm\n",
    "gamma = 0.4  # softmax scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'model' from '/home/jovyan/brain/genomegraph/learn_specific_profiles/model.py'>\n"
     ]
    }
   ],
   "source": [
    "print(importlib.reload(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 1364.37 MiB, increment: 1007.55 MiB\n",
      "CPU times: user 541 ms, sys: 416 ms, total: 957 ms\n",
      "Wall time: 1.12 s\n"
     ]
    }
   ],
   "source": [
    "# build and randomly initialize profile model\n",
    "tf.keras.backend.clear_session() # avoid memory cluttering by remains of old models\n",
    "specProModel = None\n",
    "%time %memit specProModel = model.SpecificProfile(k, su.aa_alphabet_size, U, Q, alpha=alpha, gamma=gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.42 ms, sys: 95 Âµs, total: 9.51 ms\n",
      "Wall time: 8.48 ms\n"
     ]
    }
   ],
   "source": [
    "#ds_init = dsg.getDataset(genomes, tiles_per_X, tile_size).batch(batch_size).prefetch(3)\n",
    "#%time P_logit_init = specProModel.seed_P_ds(ds_init)\n",
    "%time P_logit_init = specProModel.seed_P_genome(genomes)\n",
    "specProModel.setP_logit(P_logit_init)\n",
    "\n",
    "#%time P_logit_init = specProModel.seed_P_triplets()\n",
    "#print(specProModel.units)\n",
    "#specProModel.setP_logit(P_logit_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### See How Perfect Pattern / Repeat Profiles Score w.r.t. Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "runExperiment = False\n",
    "\n",
    "runExperiment = runExperiment and not use_real_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if runExperiment:\n",
    "    import experiment\n",
    "    print(importlib.reload(experiment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if runExperiment:\n",
    "    pProfile = tf.cast( tf.math.log( dsg.oneHot('MARIQSTANKE') + 1e-6 ), tf.float32)\n",
    "    rProfile = tf.cast( tf.math.log( dsg.oneHot('REPEATAEPER') + 1e-6 ), tf.float32)\n",
    "    \n",
    "    # build and randomly initialize profile model\n",
    "    tf.keras.backend.clear_session() # avoid memory cluttering by remains of old models\n",
    "    specProModel = None\n",
    "    specProModel = model.SpecificProfile(k, su.aa_alphabet_size, units=2, Q=Q, alpha=0, gamma=gamma)\n",
    "\n",
    "    pInit = specProModel._getRandomProfiles()\n",
    "    pInit[:,:,0] = pProfile.numpy()\n",
    "    pInit[:,:,1] = rProfile.numpy()\n",
    "    print(pInit.shape)\n",
    "\n",
    "    specProModel.setP_logit(pInit)\n",
    "    print(specProModel.P_logit.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if runExperiment:\n",
    "    #pscores = experiment.getLossScores(specProModel, 0, genomes, N, tiles_per_X, tile_size, batch_size)\n",
    "    #rscores = experiment.getLossScores(specProModel, 1, genomes, N, tiles_per_X, tile_size, batch_size)\n",
    "    pscores = experiment.getLossScores_raw(specProModel, 0, genomes, tiles_per_X, tile_size, batch_size)\n",
    "    rscores = experiment.getLossScores_raw(specProModel, 1, genomes, tiles_per_X, tile_size, batch_size)\n",
    "    pscores_raw = experiment.getLossScores_raw(specProModel, 0, genomes, tiles_per_X, tile_size, batch_size, lossNorm=False)\n",
    "    rscores_raw = experiment.getLossScores_raw(specProModel, 1, genomes, tiles_per_X, tile_size, batch_size, lossNorm=False)\n",
    "    pscores_unmasked = experiment.getLossScores_raw(specProModel, 0, genomes, tiles_per_X, tile_size, batch_size, maskNonSeqScores=False)\n",
    "    rscores_unmasked = experiment.getLossScores_raw(specProModel, 1, genomes, tiles_per_X, tile_size, batch_size, maskNonSeqScores=False)\n",
    "    pscores_raw_unmasked = experiment.getLossScores_raw(specProModel, 0, genomes, tiles_per_X, tile_size, batch_size, maskNonSeqScores=False, lossNorm=False)\n",
    "    rscores_raw_unmasked = experiment.getLossScores_raw(specProModel, 1, genomes, tiles_per_X, tile_size, batch_size, maskNonSeqScores=False, lossNorm=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Draw Artificial Genomes and Pattern / Repeat Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if runExperiment:\n",
    "    #bins, vals = experiment.ownHist(pscores.reshape((-1)), 0.00000001)\n",
    "    bins, vals = experiment.ownHist(pscores_raw, 10)\n",
    "    experiment.plotOwnHist(bins, vals, precision=1)#, ylim=(0, 30))\n",
    "    #experiment.plotOwnHist(bins, vals, precision=1, ylim=(0, 30))\n",
    "    \n",
    "    bins, vals = experiment.ownHist(pscores, 1)\n",
    "    print(set([bins[i] for i in range(len(bins)) if vals[i] > 0]))\n",
    "    experiment.plotOwnHist(bins, vals, precision=1)#, ylim=(0, 30))\n",
    "    experiment.plotOwnHist(bins, vals, precision=1, ylim=(0, 30))\n",
    "    \n",
    "    #bins, vals = experiment.ownHist(pscores.reshape((-1)), 0.00000001)\n",
    "    bins, vals = experiment.ownHistRel(pscores_raw_unmasked, 10)\n",
    "    experiment.plotOwnHist(bins, vals, precision=1)#, ylim=(0, 30))\n",
    "    #experiment.plotOwnHist(bins, vals, precision=1, ylim=(0, 30))\n",
    "    \n",
    "    bins, vals = experiment.ownHistRel(pscores_unmasked, 1)\n",
    "    print(set([bins[i] for i in range(len(bins)) if vals[i] > 0]))\n",
    "    experiment.plotOwnHist(bins, vals, precision=1)#, ylim=(0, 30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if runExperiment:\n",
    "    #bins, vals = experiment.ownHist(pscores.reshape((-1)), 0.00000001)\n",
    "    bins, vals = experiment.ownHist(rscores_raw, 10)\n",
    "    experiment.plotOwnHist(bins, vals, precision=1)#, ylim=(0, 30))\n",
    "    #experiment.plotOwnHist(bins, vals, precision=1, ylim=(0, 30))\n",
    "    \n",
    "    bins, vals = experiment.ownHist(rscores, 1)\n",
    "    print(set([bins[i] for i in range(len(bins)) if vals[i] > 0]))\n",
    "    experiment.plotOwnHist(bins, vals, precision=1)#, ylim=(0, 30))\n",
    "    experiment.plotOwnHist(bins, vals, precision=1, ylim=(0, 30))\n",
    "    \n",
    "    #bins, vals = experiment.ownHist(pscores.reshape((-1)), 0.00000001)\n",
    "    bins, vals = experiment.ownHistRel(rscores_raw_unmasked, 10)\n",
    "    experiment.plotOwnHist(bins, vals, precision=1)#, ylim=(0, 30))\n",
    "    #experiment.plotOwnHist(bins, vals, precision=1, ylim=(0, 30))\n",
    "    \n",
    "    bins, vals = experiment.ownHistRel(rscores_unmasked, 1)\n",
    "    print(set([bins[i] for i in range(len(bins)) if vals[i] > 0]))\n",
    "    experiment.plotOwnHist(bins, vals, precision=1)#, ylim=(0, 30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Draw Genomes, Pattern and Repeat Locations, and Loss Scores for each Position\n",
    "\n",
    "(scores: thin lines; top line: pattern profile (`MARIQSTANKE`), bottom line: repeat profile (`REPEATAEPER`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if runExperiment:\n",
    "    #experiment.drawLossScores(pscores, rscores, genomes, N, insertTracking, repeatTracking, tile_size)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if runExperiment:\n",
    "    # reset model\n",
    "    tf.keras.backend.clear_session() # avoid memory cluttering by remains of old models\n",
    "    specProModel = None\n",
    "    %time %memit specProModel = model.SpecificProfile(k, su.aa_alphabet_size, U, Q, alpha=alpha, gamma=gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "    Training on seedFinding data takes 5.5 h for 10 epochs on greifserv3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time()\n",
    "specProModel.train(genomes, tiles_per_X, tile_size, \n",
    "                   batch_size, steps_per_epoch, epochs=50, \n",
    "                   profile_plateau=10, profile_plateau_dev=0.5,\n",
    "                   verbose_freq=10, n_best_profiles=5, match_score_factor=0.7)\n",
    "end = time()\n",
    "print(f\"time: {end-start:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotHistory(specProModel.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize resulting profiles as sequence logos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False: # profiles after last report are just seeds\n",
    "    ds_score = dsg.getDataset(genomes, tiles_per_X, tile_size).batch(batch_size).prefetch(3)\n",
    "    printExpectedPatterns()\n",
    "    P = specProModel.getP()\n",
    "    #pScores = specProModel.max_profile_scores(ds_score)\n",
    "    #plotLogo(P=P, idxarray = np.argsort(-pScores), pScores=pScores, max_print=20)\n",
    "    pLosses = specProModel.min_profile_losses(ds_score)\n",
    "    plotLogo(P=P, idxarray = np.argsort(pLosses), pScores=pLosses, max_print=5, label=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printExpectedPatterns()\n",
    "P, Pthresh = specProModel.getP_report()\n",
    "plotLogo(P=P, pScores=Pthresh, max_print=10, label=\"Score Threshold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STOP HERE IF `RUN ALL CELLS`\n",
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getKmersFromSites(sites, genomes, k, P, Q, epsilon=1e-6):\n",
    "    kmers = []\n",
    "    kDNA = k*3\n",
    "    for site in sites:\n",
    "        g = site[0].numpy()\n",
    "        c = site[1].numpy()\n",
    "        a = site[2].numpy()\n",
    "        if a < 0:\n",
    "            kmers.append(\"\")\n",
    "            continue\n",
    "            \n",
    "        b = min(len(genomes[g][c]), a+kDNA)\n",
    "        f = str(site[4].numpy()) if len(site) >= 5 else \"\"\n",
    "        dna = genomes[g][c][a:b]\n",
    "        dnaUC = dna.upper()\n",
    "        dnaPre = genomes[g][c][max(0,a-kDNA):a]\n",
    "        dnaPost = genomes[g][c][b:min(len(genomes[g][c]), b+kDNA)]\n",
    "        aa = dsg.sequence_translation(dnaUC)\n",
    "        aaRC = dsg.sequence_translation(dnaUC, True)\n",
    "        \n",
    "        # re-calculate score\n",
    "        if len(aa) == k:\n",
    "            score = tf.reduce_sum(\n",
    "                tf.math.multiply( dsg.oneHot(aa),\n",
    "                                  tf.math.log( tf.maximum( tf.divide(P, Q), epsilon) ) \n",
    "                                ) \n",
    "            ).numpy()\n",
    "            scoreRC = tf.reduce_sum(\n",
    "                tf.math.multiply( dsg.oneHot(aaRC),\n",
    "                                  tf.math.log( tf.maximum( tf.divide(P, Q), epsilon) ) \n",
    "                                ) \n",
    "            ).numpy()\n",
    "        else:\n",
    "            score = None\n",
    "            scoreRC = None\n",
    "        \n",
    "        kmers.append(dnaPre+\" \"+dna+\" \"+dnaPost+\"   \"+aa+\" // \"+aaRC+\"   \"+str(g)+\", \"+str(c)+\", \"+f+\"   \"+str(a)+\"   \"+str(score)+\" // \"+str(scoreRC))\n",
    "        \n",
    "    return kmers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# un-mask dataset\n",
    "ucgenomes = []\n",
    "for g in range(len(genomes)):\n",
    "    ucgenomes.append([])\n",
    "    for c in range(len(genomes[g])):\n",
    "        ucgenomes[g].append( genomes[g][c].upper() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P, Pthresh = specProModel.getP_report()\n",
    "specProModel.setP_logit(specProModel.getP_report_raw()) # set reported P as profiles, otherwise get matches from randomly chosen seeds\n",
    "ds_sites = dsg.getDataset(ucgenomes, tiles_per_X, tile_size, True).batch(batch_size).prefetch(3)\n",
    "sites, scores = specProModel.get_profile_match_sites(ds_sites, 0, 1)\n",
    "assert len(sites) < 100, print(sites.shape)\n",
    "idx = tf.reshape( tf.argsort(scores, axis=0, direction='DESCENDING'), (-1))\n",
    "kmers = getKmersFromSites(sites, genomes, specProModel.k, P[:,:,1], specProModel.Q, specProModel.epsilon)\n",
    "\n",
    "print(tf.gather(scores ,idx), tf.gather(kmers, idx), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,_=printExpectedPatterns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsg.sequence_translation('cagagaacctgaagctactgctgaacctgaaag'.upper())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profile Score Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def customHist(distType: str, prec = 1):\n",
    "    validDistTypes = ['score', 'loss', 'L5score']\n",
    "    assert distType in validDistTypes, \"distType must be one of \"+str(validDistTypes)\n",
    "    \n",
    "    collect = {}\n",
    "    ds_score = getDataset().batch(batch_size).prefetch(3)\n",
    "    for batch in ds_score:\n",
    "        for X in batch:\n",
    "            S, _, _ = specProModel(X)\n",
    "            if distType == 'score':\n",
    "                for s in np.array(S).flatten():\n",
    "                    score = np.math.floor(s*prec)\n",
    "                    if score not in collect:\n",
    "                        collect[score] = 0\n",
    "                        \n",
    "                    collect[score] += 1\n",
    "                    \n",
    "            if distType == 'loss':\n",
    "                _, LpU, _ = specProModel.loss(S)\n",
    "                for l in LpU:\n",
    "                    loss = np.math.floor(l*prec)\n",
    "                    if loss not in collect:\n",
    "                        collect[loss] = 0\n",
    "                        \n",
    "                    collect[loss] += 1\n",
    "                    \n",
    "            if distType == 'L5score':\n",
    "                gamma = .2\n",
    "                S2 = tf.nn.softmax(gamma*S, axis=0)\n",
    "                S3 = tf.math.multiply(S, tf.square(S2))\n",
    "                for s in np.array(S3).flatten():\n",
    "                    score = np.math.floor(s*prec)\n",
    "                    if score not in collect:\n",
    "                        collect[score] = 0\n",
    "                        \n",
    "                    collect[score] += 1\n",
    "                    \n",
    "    fkeys = [k for k in collect.keys()]\n",
    "    bins = [b for b in range(min(fkeys), max(fkeys)+1)]\n",
    "    vals = [collect[k] if k in collect else 0 for k in bins]\n",
    "    bins = [b/prec for b in bins]\n",
    "    \n",
    "    plt.bar(list(range(len(bins))), vals, tick_label=[str(b) for b in bins])\n",
    "    \n",
    "    return bins, vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins, vals = customHist('L5score', 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins, vals = customHist('loss', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins, vals = customHist('score', 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "     P:     (k, alphSize, U) \n",
    "     X:     (tilesPerX, N, 6, T, alphSize) \n",
    "     Z:     (tilesPerX, N, 6, T-k+1, U)\n",
    "     S:     (tilesPerX, N, U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Scollect = []\n",
    "Lcollect = []\n",
    "\n",
    "if not use_real_data:\n",
    "    ds_score = getDataset().batch(batch_size).prefetch(150)\n",
    "    for batch in ds_score:\n",
    "        for X in batch:\n",
    "            S, _, Z = specProModel(X)\n",
    "            _, LpU, _ = specProModel.loss(S)\n",
    "            Scollect.extend(np.array(S).flatten())\n",
    "            Lcollect.extend(np.array(LpU).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(Scollect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(Lcollect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not use_real_data:\n",
    "    gamma = .01 # a small value means a more inclusive meaning of near-best\n",
    "    S2 = tf.nn.softmax(gamma*S, axis=0)\n",
    "    S3 = tf.reduce_max(S2, axis=0) # the closer to 1, the clearer is the champion match a winner\n",
    "    S4 = tf.reduce_max(S, axis=0) # ranges over tiles, or soft max like in L1\n",
    "    S5 = tf.math.multiply(S4, S3) # effectively the best score per genome is divided by the number of matches\n",
    "    loss_by_unit = tf.reduce_sum(S5, axis=0) / U # sum over genomes\n",
    "    L5 = tf.reduce_sum(loss_by_unit) # sum over profiles=units\n",
    "    plt.hist(S4[:,0].numpy().flatten(), bins=20)\n",
    "    S5.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Profile Match Sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# un-mask dataset\n",
    "for g in range(len(genomes)):\n",
    "    for c in range(len(genomes[g])):\n",
    "        genomes[g][c] = genomes[g][c].upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_sites = dsg.getDataset(genomes, tiles_per_X, tile_size, True).batch(batch_size).prefetch(3)\n",
    "specProModel.setP_logit(tf.math.log(specProModel.getP_report())) # set reported P as profiles, otherwise get matches from randomly chosen seeds\n",
    "sites = specProModel.get_profile_match_sites(ds_sites, 8.8)\n",
    "sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotLogo(P=specProModel.getP_report()[:,:,2:3], max_print=1, label=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(importlib.reload(dsg))\n",
    "print(genomes[2][28][25029:25029+33])\n",
    "print(dsg.sequence_translation( genomes[2][28][25029:25029+33] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def sitesToLinks(sites):\n",
    "    links = []\n",
    "    profileToOcc = {}\n",
    "    linkProfiles = set()\n",
    "    for g, c, p, u in sites:\n",
    "        if u not in profileToOcc:\n",
    "            profileToOcc[u] = {}\n",
    "            \n",
    "        if g not in profileToOcc[u]:\n",
    "            profileToOcc[u][g] = []\n",
    "            \n",
    "        profileToOcc[u][g].append([g,c,p])\n",
    "        \n",
    "    for p in profileToOcc:\n",
    "        if (len(profileToOcc[p].keys()) == 1) or (0 not in profileToOcc[p]):\n",
    "            continue\n",
    "            \n",
    "        occs = []\n",
    "        for g in profileToOcc[p]:\n",
    "            occs.append(profileToOcc[p][g])\n",
    "            \n",
    "        l = itertools.product(*occs)\n",
    "        links.extend(l)\n",
    "        linkProfiles.add(p)\n",
    "    \n",
    "    return links, linkProfiles\n",
    "\n",
    "links, linkProfiles = sitesToLinks(sites.numpy())\n",
    "print(links[:5])\n",
    "print(linkProfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(insertTracking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize Profile Matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxplot = 4\n",
    "nplot = 0\n",
    "P = specProModel.getP()\n",
    "for g in list(sites.keys()):\n",
    "    for c in list(sites[g].keys()):\n",
    "        gseq = genomes[g][c]\n",
    "        for i in range(len(sites[g][c]['profile'])):\n",
    "            p = sites[g][c]['profile'][i]\n",
    "            pos = sites[g][c]['pos'][i]\n",
    "            score = sites[g][c]['score'][i]\n",
    "            f = sites[g][c]['frame'][i]\n",
    "            \n",
    "            match = gseq[pos:(pos+specProModel.k*3)+2]\n",
    "            match_aa = su.six_frame_translation(match)\n",
    "            profile_df = su.makeDFs(P[:,:,p:(p+1)].numpy())[0]\n",
    "            logo = logomaker.Logo(profile_df, vpad=.1, width=1)\n",
    "            logo.style_xticks(anchor=0, spacing=1, rotation=45)\n",
    "            logo.ax.set_ylabel('information (bits)')\n",
    "            logo.ax.set_title(f\"Profile {p}\" + (f\" score={score:.1f}\") + \" | sequence match (frame \"+str(f)+\") \"+', '.join(match_aa))\n",
    "            \n",
    "            nplot += 1\n",
    "            if nplot >= maxplot:\n",
    "                break\n",
    "                \n",
    "        if nplot >= maxplot:\n",
    "            break\n",
    "            \n",
    "    if nplot >= maxplot:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _ = printExpectedPatterns()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \"Sensitivity\" of Profile Matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseSequenceHeader(header):\n",
    "    fields = header.split(\"|\")\n",
    "    headDict = {}\n",
    "    for field in fields:\n",
    "        key, value = field.split(\":\")\n",
    "        assert len(field.split(\":\")) == 2, header\n",
    "        assert key not in headDict, header\n",
    "        headDict[key] = value\n",
    "\n",
    "    return headDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(datapath, \"../hg38.GTF.json\"), 'rt') as fh:\n",
    "    gtf = json.load(fh)\n",
    "    \n",
    "gtf['ENST00000219797'][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(datapath, \"../orthologs.json\"), 'rt') as fh:\n",
    "    orthology = json.load(fh)\n",
    "    \n",
    "orthology[list(orthology.keys())[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqnames[0][0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nexons = 0\n",
    "northo = 0\n",
    "for seq in seqnames[0]:\n",
    "    seqDict = parseSequenceHeader(seq)\n",
    "    if seqDict['tid'] != 'artificial':\n",
    "        northo += 1\n",
    "    if seqDict['tid'] in gtf:\n",
    "        nexons += len([1 for annot in gtf[seqDict['tid']] if annot['feature'] == 'CDS'])\n",
    "        \n",
    "print(nexons)\n",
    "print(northo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tolerance = 0#3*k + 3 # allow certain position mismatch in human exons\n",
    "tp = [] # accumulate scores\n",
    "tp_links = [] # collect links for further investigation\n",
    "fp = []\n",
    "noise = []\n",
    "geneNoise = []\n",
    "exonsFound = set()\n",
    "featuresFound = set()\n",
    "orthoFound = set()\n",
    "for link in links:\n",
    "    allArt = True\n",
    "    allGen = True\n",
    "    for occ in link:\n",
    "        #print(\"DEBUG\", occ)\n",
    "        seqname = seqnames[occ[0]][occ[1]]\n",
    "        seqDict = parseSequenceHeader(seqname)\n",
    "        if seqDict['gid'] == 'artificial':\n",
    "            allGen = False\n",
    "        else:\n",
    "            allArt = False\n",
    "            \n",
    "    mscore = 0#np.mean([o[3] for o in link])\n",
    "    if allArt:\n",
    "        fp.append(mscore)\n",
    "    elif not (allArt or allGen):\n",
    "        noise.append(mscore)\n",
    "    else:\n",
    "        assert allGen\n",
    "        rSeq = seqnames[link[0][0]][link[0][1]]\n",
    "        assert rSeq in orthology, rSeq\n",
    "        if all([seqnames[o[0]][o[1]] in orthology[rSeq] for o in link[1:]]):\n",
    "            tp.append(mscore)\n",
    "            tp_links.append(link)\n",
    "            orthoFound.add(rSeq)\n",
    "            seqDict = parseSequenceHeader(rSeq)\n",
    "            tid = seqDict['tid']\n",
    "            pos = link[0][2]\n",
    "            if tid in gtf:\n",
    "                for feature in gtf[tid]:\n",
    "                    if feature['rstart']-tolerance <= pos and pos <= feature['rend']+tolerance:\n",
    "                        featuresFound.add(str(feature))\n",
    "                        if feature['feature'] == 'CDS':\n",
    "                            exonsFound.add(feature['tag'])\n",
    "                    else:\n",
    "                        print(\"[DEBUG]\", pos, \"not in\", feature['rstart'], feature['rend'], \"(\", feature['feature'],\")\")\n",
    "        else:\n",
    "            geneNoise.append(mscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TP:\", len(tp), \"| mean score:\", sum(tp)/len(tp) if len(tp) > 0 else 0)\n",
    "print(\"FP:\", len(fp), \"| mean score:\", sum(fp)/len(fp) if len(fp) > 0 else 0)\n",
    "print(\"noise:\", len(noise), \"| mean score:\", sum(noise)/len(noise) if len(noise) > 0 else 0)\n",
    "print(\"geneNoise:\", len(geneNoise), \"| mean score:\", sum(geneNoise)/len(geneNoise) if len(geneNoise) > 0 else 0)\n",
    "\n",
    "print(\"Sn:\", len(exonsFound), \"/\", nexons, \"=\", len(exonsFound)/nexons)\n",
    "print(\"hits:\", len(orthoFound), \"/\", northo, \"=\", len(orthoFound)/northo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqnames[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in featuresFound:\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Histogram(x=tp, name=\"TP\", histnorm='probability'))\n",
    "fig.add_trace(go.Histogram(x=fp, name=\"FP\", histnorm='probability'))\n",
    "fig.add_trace(go.Histogram(x=noise, name=\"noise\", histnorm='probability'))\n",
    "fig.add_trace(go.Histogram(x=geneNoise, name=\"geneNoise\", histnorm='probability'))\n",
    "\n",
    "# Overlay both histograms and reduce opacity to see both histograms\n",
    "#fig.update_layout(barmode='overlay')\n",
    "#fig.update_traces(opacity=0.75)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False # stop here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(P[:,:,0][0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profileToMEME(p, Q, i):\n",
    "    assert p.shape[1] == len(Q), str(p.shape)+\", \"+str(len(Q))\n",
    "    assert p.shape[1] == len(su.aa_alphabet[1:]), str(p.shape)+\", \"+str(len(su.aa_alphabet[1:]))\n",
    "    \n",
    "    text = 'MEME version 4\\n'\n",
    "    text += 'ALPHABET \"extProtein\" PROTEIN-LIKE\\n'\n",
    "    for aa in su.aa_alphabet[1:]:\n",
    "        text += aa+\"\\n\"\n",
    "        \n",
    "    text += 'END ALPHABET\\n'\n",
    "    text += \"Background letter frequencies\\n\"\n",
    "    freq = \" \".join([su.aa_alphabet[i+1]+\" \"+str(Q[i]) for i in range(len(Q))])\n",
    "    text += freq+\"\\n\"\n",
    "    text += \"MOTIF \"+str(i)+\" \"+str(i)+\"\\n\"\n",
    "    text += \"letter-probability matrix: alength= \"+str(p.shape[1])+\" w= \"+str(p.shape[0])+\"\\n\"\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    AC  MA0001.1\n",
    "    XX\n",
    "    ID  AGL3\n",
    "    XX\n",
    "    DE  MA0001.1 AGL3; from JASPAR\n",
    "    PO       A     C     G     T\n",
    "    1        0    94     1     2\n",
    "    2        3    75     0    19\n",
    "    3       79     4     3    11\n",
    "    4       40     3     4    50\n",
    "    5       66     1     1    29\n",
    "    6       48     2     0    47\n",
    "    7       65     5     5    22\n",
    "    8       11     2     3    81\n",
    "    9       65     3    28     1\n",
    "    10       0     3    88     6\n",
    "    XX\n",
    "    CC  program: jaspar\n",
    "    XX\n",
    "    //"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profileToTransfac(p, i):\n",
    "    assert p.shape[1] == len(su.aa_alphabet[1:]), str(p.shape)+\", \"+str(len(su.aa_alphabet[1:]))\n",
    "    text = \"AC  \"+str(i)+\"\\n\"\n",
    "    text += \"XX\\n\"\n",
    "    text += \"ID  \"+str(i)+\"\\n\"\n",
    "    text += \"XX\\n\"\n",
    "    text += \"DE  \"+str(i)+\"\\n\"\n",
    "    text += \"PO  \"+(\" \".join([su.aa_alphabet[i+1] for i in range(len(Q))]))+\"\\n\"\n",
    "    for i in range(p.shape[0]):\n",
    "        text += str(i+1)+\"  \"+(\" \".join(str(v) for v in p.numpy()[i]))+\"\\n\"\n",
    "        \n",
    "    text += \"XX\\n\"\n",
    "    text += \"CC  program: own\\n\"\n",
    "    text += \"//\"\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(profileToTransfac(P[:,:,0], 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/nas-hs/users/matthis/genomegraph/testProfileTransfacOutput.txt\", 'wt') as fh:\n",
    "    for i in range(P.shape[2]):\n",
    "        fh.write(profileToTransfac(P[:,:,i], i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosineSim(a: np.ndarray, b: np.ndarray):\n",
    "    assert len(a) == len(b)\n",
    "    return np.sum(a*b) / (np.sqrt(np.sum(np.square(a))) * np.sqrt(np.sum(np.square(b))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosineSim(np.array([0,1,0,0]), np.array([1,0,0,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified version of https://gist.github.com/nornagon/6326a643fc30339ece3021013ed9b48c\n",
    "# enforce gapless alignment\n",
    "def smith_waterman(a, b) -> float:\n",
    "    assert a.shape[1] == b.shape[1], str(a.shape)+\", \"+str(b.shape)\n",
    "    # H holds the alignment score at each point, computed incrementally\n",
    "    H = np.zeros((a.shape[0] + 1, b.shape[0] + 1))\n",
    "    for i in range(1, a.shape[0] + 1):\n",
    "        for j in range(1, b.shape[0] + 1):\n",
    "            # The score for substituting the letter a[i-1] for b[j-1]. Generally low\n",
    "            # for mismatch, high for match.\n",
    "            H[i,j] = H[i-1,j-1] + cosineSim(a[i-1], b[j-1])\n",
    "    # The highest score is the best local alignment.\n",
    "    # For our purposes, we don't actually care _what_ the alignment was, just how\n",
    "    # aligned the two strings were.\n",
    "    return H.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profileLogo(i, title=\"\", P=P):\n",
    "    profile_df = su.makeDFs(P[:,:,i:(i+1)].numpy())[0]\n",
    "    logo = logomaker.Logo(profile_df, vpad=.1, width=1)\n",
    "    logo.style_xticks(anchor=0, spacing=1, rotation=45)\n",
    "    logo.ax.set_ylabel('information (bits)')\n",
    "    logo.ax.set_title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = P[:,:,0]\n",
    "profileLogo(0, \"Reference profile\")\n",
    "\n",
    "for i in range(5653,5658):\n",
    "    b = P[:,:,i]\n",
    "    s = smith_waterman(a,b)\n",
    "    profileLogo(i, \"Aligning with score \"+str(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(P.shape[2]):\n",
    "    for j in range(i+1, P.shape[2]):\n",
    "        if smith_waterman(P[:,:,i], P[:,:,j]) >= P.shape[0]/2:\n",
    "            print(\"Similar:\",i,\"and\",j)\n",
    "            profileLogo(i,str(i))\n",
    "            profileLogo(j,str(j))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Best Profiles\n",
    "\n",
    "Idea: \n",
    "* convert profiles into aa-sequences (translate max. values into aa at each position)\n",
    "* align (or perfect match?) sequences against the 6 possible pattern translations and the insert translations\n",
    "* alignment scores give an idea of how good the profiles are -> allows multiple training runs to account for randomness, evaluate how good the profiles usually are (+ variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import pairwise2\n",
    "from Bio.pairwise2 import format_alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runTraining():\n",
    "    tf.keras.backend.clear_session() # avoid memory cluttering by remains of old models\n",
    "    \n",
    "    # build and randomly initialize profile model\n",
    "    specProModel = SpecificProfile(k, su.aa_alphabet_size, U, Q)\n",
    "    \n",
    "    #start = time()\n",
    "    specProModel.train_ds(ds, steps_per_epoch, epochs=500, verbose=False)\n",
    "    #end = time()\n",
    "    #print(f\"time: {end-start:.2f}\")\n",
    "    \n",
    "    #S, R = specProModel(X)\n",
    "    #_, (L1, L2, L4, L7) = specProModel.loss(S)\n",
    "    #pScores = tf.reduce_sum(tf.reduce_max(S,axis=0), axis=0).numpy()\n",
    "    #print(\"pScores\", pScores)\n",
    "    #np.argsort(pScores)\n",
    "    #print (\"loss=\", L1.numpy(), \"\\tL2=\", L2.numpy(), \n",
    "    #       \"\\tL4=\", L4.numpy(), \"\\nS=\", S.numpy())\n",
    "    \n",
    "    P = specProModel.getP()\n",
    "    \n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aaFromProfiles(P):\n",
    "    profiles_aa = []\n",
    "    for pidx in range(P.shape[2]):\n",
    "        pmat = P[:,:,pidx]\n",
    "        profiles_aa.append(su.to_aa_seq(pmat))\n",
    "\n",
    "    return profiles_aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBestAlignments(profiles, patterns, scoreThreshold = int(k/2)):\n",
    "    scores = []\n",
    "    alignments = []\n",
    "    best_profiles = []\n",
    "    for profile in profiles:\n",
    "        pscores = []\n",
    "        palignments = []\n",
    "        for pattern in patterns:\n",
    "            als = pairwise2.align.localxd(profile, pattern, openA=-1000, extendA=-1000, openB=-1000, extendB=-1000)\n",
    "            s = [al.score for al in als]\n",
    "            if len(s) > 0:\n",
    "                pscores.append(np.argmax(s))\n",
    "                palignments.append(als[np.argmax(s)])\n",
    "\n",
    "        best_al = palignments[np.argmax(pscores)]\n",
    "        if best_al.score >= scoreThreshold:\n",
    "            scores.append(best_al.score)\n",
    "            alignments.append(best_al)\n",
    "            best_profiles.append(profile)\n",
    "\n",
    "    if len(scores) > 0:\n",
    "        sortedIdx = np.argsort([-s for s in scores])\n",
    "        scores = [scores[i] for i in sortedIdx]\n",
    "        alignments = [alignments[i] for i in sortedIdx]\n",
    "        best_profiles = [best_profiles[i] for i in sortedIdx]\n",
    "    \n",
    "    return scores, alignments, best_profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    for i in range(20):\n",
    "        P = runTraining()\n",
    "        profiles = aaFromProfiles(P)\n",
    "        print(\"Run\", i)\n",
    "        if insertPatterns is not None:\n",
    "            print(\"Desired profiles:\")\n",
    "            patternScores, patternAlignments, patternProfiles = getBestAlignments(profiles, desiredPatternAA)\n",
    "            for i in range(len(patternScores)):\n",
    "                    print(patternProfiles[i])\n",
    "                    print(format_alignment(*(patternAlignments[i])))\n",
    "\n",
    "        if repeatPatterns is not None:\n",
    "            print(\"Undesired profiles:\")\n",
    "            repeatScores, repeatAlignments, repeatProfiles = getBestAlignments(profiles, repeatPatternAA)\n",
    "            for i in range(len(repeatScores)):\n",
    "                    print(repeatProfiles[i])\n",
    "                    print(format_alignment(*(repeatAlignments[i])))\n",
    "\n",
    "        print(\"\")\n",
    "        print(\"-----\")\n",
    "        print(\"\")\n",
    "        \n",
    "else:\n",
    "    P = specProModel.getP()\n",
    "    profiles = aaFromProfiles(P)\n",
    "\n",
    "    if insertPatterns is not None:\n",
    "        print(\"Desired profiles:\")\n",
    "        patternScores, patternAlignments, patternProfiles = getBestAlignments(profiles, desiredPatternAA, scoreThreshold=4)\n",
    "        for i in range(len(patternScores)):\n",
    "                print(patternProfiles[i])\n",
    "                print(format_alignment(*(patternAlignments[i])))\n",
    "\n",
    "    if repeatPatterns is not None:\n",
    "        print(\"Undesired profiles:\")\n",
    "        repeatScores, repeatAlignments, repeatProfiles = getBestAlignments(profiles, repeatPatternAA, scoreThreshold=4)\n",
    "        for i in range(len(repeatScores)):\n",
    "            print(repeatProfiles[i])\n",
    "            print(format_alignment(*(repeatAlignments[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = specProModel.getR()\n",
    "profiles = aaFromProfiles(R)\n",
    "if insertPatterns is not None:\n",
    "    print(\"Desired profiles:\")\n",
    "    patternScores, patternAlignments, patternProfiles = getBestAlignments(profiles, desiredPatternAA, scoreThreshold=4)\n",
    "    for i in range(len(patternScores)):\n",
    "            print(patternProfiles[i])\n",
    "            print(format_alignment(*(patternAlignments[i])))\n",
    "\n",
    "if repeatPatterns is not None:\n",
    "    print(\"Undesired profiles:\")\n",
    "    repeatScores, repeatAlignments, repeatProfiles = getBestAlignments(profiles, repeatPatternAA, scoreThreshold=4)\n",
    "    for i in range(len(repeatScores)):\n",
    "        print(repeatProfiles[i])\n",
    "        print(format_alignment(*(repeatAlignments[i])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Evaluate Parameter Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import time, datetime\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfN = pd.read_csv(\"20211111_evaluate_gensize_N.csv\")\n",
    "dfGS = pd.read_csv(\"20211111_evaluate_gensize_GS.csv\")\n",
    "dfNS = pd.read_csv(\"20211111_evaluate_gensize_NS.csv\")\n",
    "print(dfN)\n",
    "print(dfGS)\n",
    "print(dfNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeFromStr(tstr: str):\n",
    "    h,m,s = tstr.split(\":\")\n",
    "    s, us = s.split(\".\")\n",
    "    us = float(\"0.\"+us) * 1000000\n",
    "    #print(h,m,s,us)\n",
    "    return time(int(h),int(m),int(s), int(us))\n",
    "\n",
    "def secondsFromStr(tstr: str):\n",
    "    h,m,s = tstr.split(\":\")\n",
    "    seconds = (int(h)*60*60) + (int(m)*60) + float(s)\n",
    "    return seconds\n",
    "    \n",
    "runtime = [secondsFromStr(s) for s in df['runtime']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=df['U'], y=runtime, name=\"runtime\"))\n",
    "fig.update_xaxes(title_text='U')\n",
    "fig.update_yaxes(title_text='runtime [s]')#, type='log')\n",
    "fig.show()\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=df['U'], y=df['memory'], name=\"memory [MB]\"))\n",
    "fig.update_xaxes(title_text='U')\n",
    "fig.update_yaxes(title_text='Memory [MB]')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsN = []\n",
    "for _, row in dfN.iterrows():\n",
    "    gsN.append(int(row['N']) * int(row['genome-sizes']))\n",
    "    \n",
    "gsGS = []\n",
    "for _, row in dfGS.iterrows():\n",
    "    gsGS.append(int(row['N']) * int(row['genome-sizes']))\n",
    "    \n",
    "gsNS = []\n",
    "for _, row in dfNS.iterrows():\n",
    "    gs = [int(s) for s in row['genome-sizes'].split()]\n",
    "    gsNS.append(int(row['N']) * sum(gs))\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=gsN, y=[secondsFromStr(s) for s in dfN['runtime']], name=\"runtime N\"))\n",
    "fig.add_trace(go.Scatter(x=gsGS, y=[secondsFromStr(s) for s in dfGS['runtime']], name=\"runtime GS\"))\n",
    "fig.add_trace(go.Scatter(x=gsNS, y=[secondsFromStr(s) for s in dfNS['runtime']], name=\"runtime NS\"))\n",
    "fig.update_xaxes(title_text='genome size')\n",
    "fig.update_yaxes(title_text='runtime [s]')\n",
    "fig.show()\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=gsN, y=dfN['memory'], name=\"memory [MB] N\"))\n",
    "fig.add_trace(go.Scatter(x=gsGS, y=dfGS['memory'], name=\"memory [MB] GS\"))\n",
    "fig.add_trace(go.Scatter(x=gsNS, y=dfNS['memory'], name=\"memory [MB] NS\"))\n",
    "fig.update_xaxes(title_text='genome size')\n",
    "fig.update_yaxes(title_text='Memory [MB]')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "yr = []\n",
    "ym = []\n",
    "for _, row in dfN.iterrows():\n",
    "    x.append(int(row['N']))\n",
    "    yr.append(secondsFromStr(row['runtime']))\n",
    "    ym.append(float(row['memory']))\n",
    "    \n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=yr, name=\"runtime\"))\n",
    "fig.update_xaxes(title_text='genome size')\n",
    "fig.update_yaxes(title_text='runtime [s]')\n",
    "fig.show()\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=ym, name=\"memory [MB] N\"))\n",
    "fig.update_xaxes(title_text='genome size')\n",
    "fig.update_yaxes(title_text='Memory [MB]')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "yr = []\n",
    "ym = []\n",
    "for _, row in dfGS.iterrows():\n",
    "    x.append(int(row['genome-sizes']))\n",
    "    yr.append(secondsFromStr(row['runtime']))\n",
    "    ym.append(float(row['memory']))\n",
    "    \n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=yr, name=\"runtime\"))\n",
    "fig.update_xaxes(title_text='genome size')\n",
    "fig.update_yaxes(title_text='runtime [s]')\n",
    "fig.show()\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=ym, name=\"memory [MB] N\"))\n",
    "fig.update_xaxes(title_text='genome size')\n",
    "fig.update_yaxes(title_text='Memory [MB]')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "yr = []\n",
    "ym = []\n",
    "for _, row in dfNS.iterrows():\n",
    "    x.append(sum([int(s) for s in row['genome-sizes'].split()]))\n",
    "    yr.append(secondsFromStr(row['runtime']))\n",
    "    ym.append(float(row['memory']))\n",
    "    \n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=yr, name=\"runtime\"))\n",
    "fig.update_xaxes(title_text='genome size')\n",
    "fig.update_yaxes(title_text='runtime [s]')\n",
    "fig.show()\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=ym, name=\"memory [MB] N\"))\n",
    "fig.update_xaxes(title_text='genome size')\n",
    "fig.update_yaxes(title_text='Memory [MB]')\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
